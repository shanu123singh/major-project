# -*- coding: utf-8 -*-
"""Major Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R9v_dIoEohORowSbxBXyXfsvhAwr_RAZ
"""

from gettext import install
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pip
import seaborn as sns
import streamlit

df=pd.read_csv(r'C:\Users\singh\Downloads\retail_sales_prediction_dirty_outliers.csv')


df

df.head()

df.isnull().sum()

df.duplicated().sum()

sns.boxplot(df)

#droppinp the duplicate data
df.drop_duplicates(inplace=True)

df.duplicated().sum()

X=df.drop('Sales',axis=1)
y=df['Sales']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

#removing duplicate and missing values
from sklearn.impute import SimpleImputer


imputer = SimpleImputer(strategy='mean')

X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed  = imputer.transform(X_test)

X_train_si = pd.DataFrame(X_train_imputed, columns=X_train.columns)
X_test_si  = pd.DataFrame(X_test_imputed
                          , columns=X_train.columns)

X_train_si.isnull().sum()

#detecting outliers
plt.figure(figsize=(15,10))
plt.subplot(1,2,1)
sns.boxplot(X_train_si)
plt.subplot(1,2,2)
sns.boxplot(X_test_si)
plt.show()

#applying capping and treaming
Q1 = X_train_si.quantile(0.25)
Q3 = X_train_si.quantile(0.75)
IQR = Q3 - Q1

lower_limit = Q1 - 1.5 * IQR
upper_limit = Q3 + 1.5 * IQR

new_X_train = X_train_si[
    (X_train_si >= lower_limit) & (X_train_si <= upper_limit)
]

new_X_test = X_test_si[
    (X_test_si >= lower_limit) & (X_test_si <= upper_limit)
]

new1_X_train = X_train_si.clip(lower=lower_limit, upper=upper_limit, axis=1)
new1_X_test  = X_test_si.clip(lower=lower_limit, upper=upper_limit, axis=1)

new1_X_train

sns.boxplot(new1_X_train)

sns.boxplot(new1_X_test)

#applying scalling to scale the dataset
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(new1_X_train)
X_test_scaled  = scaler.transform(new1_X_test)

X_train_scaled=pd.DataFrame(X_train_scaled,columns=new1_X_train.columns)
X_test_scaled=pd.DataFrame(X_test_scaled,columns=new1_X_test.columns)

X_train_scaled

X_test_scaled

#applying gradiant boosting
from sklearn.ensemble import GradientBoostingRegressor

gbr = GradientBoostingRegressor(
    n_estimators=8,
    learning_rate=0.1,
    max_depth=2,
    random_state=42
)

gbr.fit(X_train_scaled, y_train)

y_pred = gbr.predict(X_test_scaled)

mask = ~y_test.isna()

y_test_clean = y_test[mask]
y_pred_clean = y_pred[mask]

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

print("R2-score:", r2_score(y_test_clean, y_pred_clean))
print("MAE:", mean_absolute_error(y_test_clean, y_pred_clean))
print("MSE:", mean_squared_error(y_test_clean, y_pred_clean))
print("RMSE:", np.sqrt(mean_squared_error(y_test_clean, y_pred_clean)))

import joblib

# Save Gradient Boosting model
joblib.dump(gbr, "gradient_boosting_model.joblib")

# Save Scaler
joblib.dump(scaler, "scaler.joblib")

# (Optional) Save Imputer if used
joblib.dump(imputer, "imputer.joblib")

print("All objects saved successfully!")

